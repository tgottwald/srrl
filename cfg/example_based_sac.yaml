defaults:  
  - _self_  
  - override hydra/hydra_logging: disabled  
  - override hydra/job_logging: disabled  
hydra:
  output_subdir: null
  run:
    dir: .
experiment_meta:
  experiment_name: JaxExampleBasedSAC
  track: true
  wandb_project_name: JaxExampleBasedSAC
  wandb_group_name: !!null # Default: !!null (==None in Python)
env_id: CarEnv-LidarParking-v1 # Default: CarEnv-LidarParking-v1, SafetyPointGoal3Gymnasium-v0
# seed: 0
total_timesteps: 1000000 # Default: 1000000
max_episode_steps: 300 # Default: 300 (CarEnv + SafetyPointGoal3Gymnasium), 1000 (every other SafetyGymnasium Env)
buffer_size: 300000 # 300000
cost_mode: buffer_zone_v2 # Default: buffer_zone_v2
cost_buffer_radius: 0.3 # Default: 0.3
example_count: 200 # Default: 200
gamma: 0.99 # Default: 0.99
batch_size: 128 # Default: 128
update_to_data_ratio: 1 # Default: 1 (Vanilla SAC), 20 (REDQ)
learning_starts: 5000 # Default: 5000
logging_frequency: 100 # Default: 100
eval_tries: 1 # Default: 1
eval_episode_frequency: 25000 # Default: 25000 WARNING! If this value is to small the video logging will eat up all the memory
rnd:
  predictor_lr: 0.00003 # Default: 0.00003 
  embedding_dim: 128
  batch_size: 64
  beta: 1.0 # Default: 1.0
entropy_coeff: auto # Default: auto | Set to fixed entropy coefficient value if should not be tuned automatically
actor:
  policy_lr: 0.0003 # Default: 0.0003
critic:
  ensemble_size: 2 # Default: 2 (Vanilla SAC), 10 (REDQ)
  ensemble_sample_size: 2 # Default: 2 (Vanilla SAC), 2 (REDQ)
  q_lr: 0.0003 # Default: 0.0003
  tau: 0.005 # Default: 0.005
  success_target_scaling: 1.0 # Default: 1.0
